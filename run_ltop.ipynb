{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to run the full LandTrendr Optimization (LTOP) workflow implemented in Python. This tool is intended to be used to select the 'optiumum' version of the LandTrendr change detection algorithm (Kennedy et al., 2010, 2018) for different areas on a landscape. \n",
    "\n",
    "#### Notes\n",
    "- You need to authenticate the run with a specific GEE account. In the import params statement its going to trigger the ee.Authenticate() protocal which will prompt you to a browser page to authenticate using your GEE account. \n",
    "- Subsequent scripts have just the ee.Initialize protocal because you should have already authenicated and this should only happen once. \n",
    "- Right now this is going to import the params from a separate .py file and treat those as imports. It may actually be easier/more straight forward if we're going to stick with a Jupyter Notebook to just put these directly into a cell here in the Jupyter Notebook. \n",
    "- If you import a module at the top and then change something in the exe script you will need to restart or otherwise delete variables because that change won't be reflected otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee \n",
    "import params\n",
    "import time \n",
    "import pandas as pd \n",
    "import ltop \n",
    "import importlib\n",
    "importlib.reload(ltop)\n",
    "import lt_params\n",
    "importlib.reload(lt_params)\n",
    "from run_SNIC_01 import RunSNIC\n",
    "import run_kMeans_02_1 as kmeans_1\n",
    "import run_kMeans_02_2 as kmeans_2\n",
    "import abstract_sampling_03 as ab_img\n",
    "import abstract_imager_04 as run_lt_pts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is potentially an issue here where running a cell for a large area will result in a problem with the cell hanging. This may be an issue particuarly if you're running this thing in a browser. Its also possible that it will just start a job on the GEE server and then finish running here in the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check if a task is done we can get the task status and check to see if its done. Define a little function that can be recycled below for that purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_task_status(task_dict): \n",
    "    '''\n",
    "    Input to this function should be a dictionary that is formatted \n",
    "    like the output of task.status()\n",
    "    '''\n",
    "    task_id = task_dict['id']\n",
    "    #for some reason GEE defaults this to a list with a dictioanary as its only item\n",
    "    task_status = ee.data.getTaskStatus(task_id)[0]\n",
    "    \n",
    "    return task_status['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the first SNIC step \n",
    "\n",
    "snic = RunSNIC(params)\n",
    "\n",
    "status1,status2 = snic.generate_tasks()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we run the kmeans algorithm which will automatically grab the snic outputs to do that process. This is not exposed to the user and assumes that you have specified the child and root directories where you want things to go in the params.py file. The following code block will check if the snic process is done and then when it determines that process has concluded it will execute the kmeans step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#note that if you want to just run the kmeans process without having run snic \n",
    "#uncomment the following line of code\n",
    "km_status = kmeans_1.generate_tasks(params.params)\n",
    "while True:\n",
    "    try: \n",
    "        ts_1 = check_task_status(status1) \n",
    "        ts_2 = check_task_status(status2) \n",
    "        \n",
    "        if (ts_1 == 'COMPLETED') & (ts_2 == 'COMPLETED'): \n",
    "            print('The previous task is complete')\n",
    "            km_status = kmeans_1.generate_tasks(params.params)\n",
    "            break\n",
    "        elif (ts_1 == 'FAILED') | (ts_1 == 'CANCELLED'): \n",
    "            print('The first task failed')\n",
    "            break\n",
    "        elif (ts_2 == 'FAILED') | (ts_2 == 'CANCELLED'): \n",
    "            print('The second task failed')\n",
    "            break \n",
    "    except NameError: \n",
    "        print('You did not run the snic step so there is no status to check')\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we just take the kmeans output and do a stratified random sample to get one point for each cluster id in the kmeans output image. Like the previous step, this one will also check to see if the output is done before executing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_pts_status = kmeans_2.generate_tasks(params.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create the abstract images. Previously to the Python implementation, these were created from a CSV which was generated in GEE and then pulled down to a local machine. The actual images were constructed in Numpy and then re-uploaded to GEE. This is a pretty inefficient process and therefore we are moving it to a GEE-assets generation type process. This is based on some code that Jack Kilbride wrote to replace the Numpy scheme and is still in testing as of 10/6/2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_imgs_status = ab_img.create_abstract_imgs(params.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timeseries': <ee.imagecollection.ImageCollection at 0x7f381bfacb90>,\n",
       " 'maxSegments': 6,\n",
       " 'spikeThreshold': 0.75,\n",
       " 'vertexCountOvershoot': 3,\n",
       " 'preventOneYearRecovery': True,\n",
       " 'recoveryThreshold': 0.25,\n",
       " 'pvalThrec': 0.05,\n",
       " 'bestModelProportion': 0.75,\n",
       " 'minObservationsNeeded': 6,\n",
       " 'pvalThreshold': nan}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to see if we can just make the runParams into something else\n",
    "df = pd.DataFrame.from_records(lt_params.runParams)#.reset_index()#,index=range(len(lt_params.runParams)))\n",
    "\n",
    "# df = df.head(10)\n",
    "df['timeseries'] = None\n",
    "df['timeseries'] = ee.ImageCollection([])\n",
    "output = df.to_dict(orient='records')\n",
    "\n",
    "ls = [x for x in output]\n",
    "ls[0]\n",
    "\n",
    "\n",
    "# df = df.head(1)\n",
    "# def something(x): \n",
    "#     print(x.to_frame().T.to_dict(orient='dict'))\n",
    "# df.apply(something)\n",
    "\n",
    "# test = df.iloc[0].to_frame().T\n",
    "# test.timeseries\n",
    "# df = df.apply(lambda x: print(pd.DataFrame(x).to_dict(orient='dict')))\n",
    "\n",
    "# def something(x): \n",
    "#     print(x)\n",
    "#     return None\n",
    "# test = df.head(10)\n",
    "# test = df.apply(lambda x: print(x.iloc[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run landtrendr on the abstract image points, using the indices generated in the previous step as inputs. The scripts for the 04 step should be prepped to handle assets as inputs and will expect an imageCollection of abstract images as well as the points that were generated in the previous step that show where the abstract image pixels are located (centroids). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lt_pt_status = run_lt_pts.run_LT_abstract_imgs(params.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ltop_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "757548dda17506bf7478dcf5c19d54dd277731f0c6e8d9deffb7323e66285ff1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
